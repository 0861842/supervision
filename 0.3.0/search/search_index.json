{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome","title":"\ud83d\udc4b Welcome","text":"<p>Supervision is a set of easy-to-use utilities that will come in handy in any computer vision project. </p> <p>Supervision is still in  pre-release stage \ud83d\udea7 Keep your eyes open for potential bugs and be aware that at this stage our API is still fluid and may change.</p>"},{"location":"#how-to-install","title":"\ud83d\udcbb How to Install","text":"<p>You can install <code>supervision</code> with pip in a  3.10&gt;=Python&gt;=3.7 environment.</p> <p>Pip install method (recommended)</p> <pre><code>pip install supervision\n</code></pre> <p>Git clone method (for development)</p> <p><pre><code>git https://github.com/roboflow/supervision.git\ncd supervision\npip install -e '.[dev]'\n</code></pre> See contributing section to know more about contributing to the project</p>"},{"location":"detection_core/","title":"Core","text":""},{"location":"detection_core/#detections","title":"Detections","text":"<p>Data class containing information about the detections in a video frame.</p> <p>Attributes:</p> Name Type Description <code>xyxy</code> <code>ndarray</code> <p>An array of shape <code>(n, 4)</code> containing the bounding boxes coordinates in format <code>[x1, y1, x2, y2]</code></p> <code>confidence</code> <code>Optional[ndarray]</code> <p>An array of shape <code>(n,)</code> containing the confidence scores of the detections.</p> <code>class_id</code> <code>ndarray</code> <p>An array of shape <code>(n,)</code> containing the class ids of the detections.</p> <code>tracker_id</code> <code>Optional[ndarray]</code> <p>An array of shape <code>(n,)</code> containing the tracker ids of the detections.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>@dataclass\nclass Detections:\n    \"\"\"\n    Data class containing information about the detections in a video frame.\n\n    Attributes:\n        xyxy (np.ndarray): An array of shape `(n, 4)` containing the bounding boxes coordinates in format `[x1, y1, x2, y2]`\n        confidence (Optional[np.ndarray]): An array of shape `(n,)` containing the confidence scores of the detections.\n        class_id (np.ndarray): An array of shape `(n,)` containing the class ids of the detections.\n        tracker_id (Optional[np.ndarray]): An array of shape `(n,)` containing the tracker ids of the detections.\n    \"\"\"\n\n    xyxy: np.ndarray\n    class_id: np.ndarray\n    confidence: Optional[np.ndarray] = None\n    tracker_id: Optional[np.ndarray] = None\n\n    def __post_init__(self):\n        n = len(self.xyxy)\n        validators = [\n            (isinstance(self.xyxy, np.ndarray) and self.xyxy.shape == (n, 4)),\n            (isinstance(self.class_id, np.ndarray) and self.class_id.shape == (n,)),\n            self.confidence is None\n            or (\n                isinstance(self.confidence, np.ndarray)\n                and self.confidence.shape == (n,)\n            ),\n            self.tracker_id is None\n            or (\n                isinstance(self.tracker_id, np.ndarray)\n                and self.tracker_id.shape == (n,)\n            ),\n        ]\n        if not all(validators):\n            raise ValueError(\n                \"xyxy must be 2d np.ndarray with (n, 4) shape, \"\n                \"confidence must be None or 1d np.ndarray with (n,) shape, \"\n                \"class_id must be 1d np.ndarray with (n,) shape, \"\n                \"tracker_id must be None or 1d np.ndarray with (n,) shape\"\n            )\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of detections in the Detections object.\n        \"\"\"\n        return len(self.xyxy)\n\n    def __iter__(\n        self,\n    ) -&gt; Iterator[Tuple[np.ndarray, Optional[float], int, Optional[Union[str, int]]]]:\n        \"\"\"\n        Iterates over the Detections object and yield a tuple of `(xyxy, confidence, class_id, tracker_id)` for each detection.\n        \"\"\"\n        for i in range(len(self.xyxy)):\n            yield (\n                self.xyxy[i],\n                self.confidence[i] if self.confidence is not None else None,\n                self.class_id[i],\n                self.tracker_id[i] if self.tracker_id is not None else None,\n            )\n\n    def __eq__(self, other: Detections):\n        return all(\n            [\n                np.array_equal(self.xyxy, other.xyxy),\n                any(\n                    [\n                        self.confidence is None and other.confidence is None,\n                        np.array_equal(self.confidence, other.confidence),\n                    ]\n                ),\n                np.array_equal(self.class_id, other.class_id),\n                any(\n                    [\n                        self.tracker_id is None and other.tracker_id is None,\n                        np.array_equal(self.tracker_id, other.tracker_id),\n                    ]\n                ),\n            ]\n        )\n\n    @classmethod\n    def from_yolov5(cls, yolov5_detections):\n        \"\"\"\n        Creates a Detections instance from a YOLOv5 output Detections\n\n        Attributes:\n            yolov5_detections (yolov5.models.common.Detections): The output Detections instance from YOLOv5\n\n        Returns:\n\n        Example:\n            ```python\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; from supervision import Detections\n\n            &gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n            &gt;&gt;&gt; results = model(frame)\n            &gt;&gt;&gt; detections = Detections.from_yolov5(results)\n            ```\n        \"\"\"\n        yolov5_detections_predictions = yolov5_detections.pred[0].cpu().cpu().numpy()\n        return cls(\n            xyxy=yolov5_detections_predictions[:, :4],\n            confidence=yolov5_detections_predictions[:, 4],\n            class_id=yolov5_detections_predictions[:, 5].astype(int),\n        )\n\n    @classmethod\n    def from_yolov8(cls, yolov8_results):\n        \"\"\"\n        Creates a Detections instance from a YOLOv8 output Results\n\n        Attributes:\n            yolov8_results (ultralytics.yolo.engine.results.Results): The output Results instance from YOLOv8\n\n        Returns:\n\n        Example:\n            ```python\n            &gt;&gt;&gt; from ultralytics import YOLO\n            &gt;&gt;&gt; from supervision import Detections\n\n            &gt;&gt;&gt; model = YOLO('yolov8s.pt')\n            &gt;&gt;&gt; results = model(frame)[0]\n            &gt;&gt;&gt; detections = Detections.from_yolov8(results)\n            ```\n        \"\"\"\n        return cls(\n            xyxy=yolov8_results.boxes.xyxy.cpu().numpy(),\n            confidence=yolov8_results.boxes.conf.cpu().numpy(),\n            class_id=yolov8_results.boxes.cls.cpu().numpy().astype(int),\n        )\n\n    @classmethod\n    def from_transformers(cls, transformers_results: dict):\n        return cls(\n            xyxy=transformers_results[\"boxes\"].cpu().numpy(),\n            confidence=transformers_results[\"scores\"].cpu().numpy(),\n            class_id=transformers_results[\"labels\"].cpu().numpy().astype(int),\n        )\n\n    @classmethod\n    def from_detectron2(cls, detectron2_results):\n        return cls(\n            xyxy=detectron2_results[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n            confidence=detectron2_results[\"instances\"].scores.cpu().numpy(),\n            class_id=detectron2_results[\"instances\"]\n            .pred_classes.cpu()\n            .numpy()\n            .astype(int),\n        )\n\n    @classmethod\n    def from_coco_annotations(cls, coco_annotation: dict):\n        xyxy, class_id = [], []\n\n        for annotation in coco_annotation:\n            x_min, y_min, width, height = annotation[\"bbox\"]\n            xyxy.append([x_min, y_min, x_min + width, y_min + height])\n            class_id.append(annotation[\"category_id\"])\n\n        return cls(xyxy=np.array(xyxy), class_id=np.array(class_id))\n\n    def filter(self, mask: np.ndarray, inplace: bool = False) -&gt; Optional[Detections]:\n        \"\"\"\n        Filter the detections by applying a mask.\n\n        Attributes:\n            mask (np.ndarray): A mask of shape `(n,)` containing a boolean value for each detection indicating if it should be included in the filtered detections\n            inplace (bool): If True, the original data will be modified and self will be returned.\n\n        Returns:\n            Optional[np.ndarray]: A new instance of Detections with the filtered detections, if inplace is set to `False`. `None` otherwise.\n        \"\"\"\n        if inplace:\n            self.xyxy = self.xyxy[mask]\n            self.confidence = self.confidence[mask]\n            self.class_id = self.class_id[mask]\n            self.tracker_id = (\n                self.tracker_id[mask] if self.tracker_id is not None else None\n            )\n            return self\n        else:\n            return Detections(\n                xyxy=self.xyxy[mask],\n                confidence=self.confidence[mask],\n                class_id=self.class_id[mask],\n                tracker_id=self.tracker_id[mask]\n                if self.tracker_id is not None\n                else None,\n            )\n\n    def get_anchor_coordinates(self, anchor: Position) -&gt; np.ndarray:\n        \"\"\"\n        Returns the bounding box coordinates for a specific anchor.\n\n        Properties:\n            anchor (Position): Position of bounding box anchor for which to return the coordinates.\n\n        Returns:\n            np.ndarray: An array of shape `(n, 2)` containing the bounding box anchor coordinates in format `[x, y]`.\n        \"\"\"\n        if anchor == Position.CENTER:\n            return np.array(\n                [\n                    (self.xyxy[:, 0] + self.xyxy[:, 2]) / 2,\n                    (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n                ]\n            ).transpose()\n        elif anchor == Position.BOTTOM_CENTER:\n            return np.array(\n                [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 3]]\n            ).transpose()\n\n        raise ValueError(f\"{anchor} is not supported.\")\n\n    def __getitem__(self, index: np.ndarray) -&gt; Detections:\n        if isinstance(index, np.ndarray) and (\n            index.dtype == bool or index.dtype == int\n        ):\n            return Detections(\n                xyxy=self.xyxy[index],\n                confidence=self.confidence[index],\n                class_id=self.class_id[index],\n                tracker_id=self.tracker_id[index]\n                if self.tracker_id is not None\n                else None,\n            )\n        raise TypeError(\n            f\"Detections.__getitem__ not supported for index of type {type(index)}.\"\n        )\n\n    @property\n    def area(self) -&gt; np.ndarray:\n        return (self.xyxy[:, 3] - self.xyxy[:, 1]) * (self.xyxy[:, 2] - self.xyxy[:, 0])\n\n    def with_nms(self, threshold: float = 0.5) -&gt; Detections:\n        assert (\n            self.confidence is not None\n        ), f\"Detections confidence must be given for NMS to be executed.\"\n        indices = non_max_suppression(self.xyxy, self.confidence, threshold=threshold)\n        return self[indices]\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterates over the Detections object and yield a tuple of <code>(xyxy, confidence, class_id, tracker_id)</code> for each detection.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def __iter__(\n    self,\n) -&gt; Iterator[Tuple[np.ndarray, Optional[float], int, Optional[Union[str, int]]]]:\n    \"\"\"\n    Iterates over the Detections object and yield a tuple of `(xyxy, confidence, class_id, tracker_id)` for each detection.\n    \"\"\"\n    for i in range(len(self.xyxy)):\n        yield (\n            self.xyxy[i],\n            self.confidence[i] if self.confidence is not None else None,\n            self.class_id[i],\n            self.tracker_id[i] if self.tracker_id is not None else None,\n        )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of detections in the Detections object.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    Returns the number of detections in the Detections object.\n    \"\"\"\n    return len(self.xyxy)\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.filter","title":"<code>filter(mask, inplace=False)</code>","text":"<p>Filter the detections by applying a mask.</p> <p>Attributes:</p> Name Type Description <code>mask</code> <code>ndarray</code> <p>A mask of shape <code>(n,)</code> containing a boolean value for each detection indicating if it should be included in the filtered detections</p> <code>inplace</code> <code>bool</code> <p>If True, the original data will be modified and self will be returned.</p> <p>Returns:</p> Type Description <code>Optional[Detections]</code> <p>Optional[np.ndarray]: A new instance of Detections with the filtered detections, if inplace is set to <code>False</code>. <code>None</code> otherwise.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def filter(self, mask: np.ndarray, inplace: bool = False) -&gt; Optional[Detections]:\n    \"\"\"\n    Filter the detections by applying a mask.\n\n    Attributes:\n        mask (np.ndarray): A mask of shape `(n,)` containing a boolean value for each detection indicating if it should be included in the filtered detections\n        inplace (bool): If True, the original data will be modified and self will be returned.\n\n    Returns:\n        Optional[np.ndarray]: A new instance of Detections with the filtered detections, if inplace is set to `False`. `None` otherwise.\n    \"\"\"\n    if inplace:\n        self.xyxy = self.xyxy[mask]\n        self.confidence = self.confidence[mask]\n        self.class_id = self.class_id[mask]\n        self.tracker_id = (\n            self.tracker_id[mask] if self.tracker_id is not None else None\n        )\n        return self\n    else:\n        return Detections(\n            xyxy=self.xyxy[mask],\n            confidence=self.confidence[mask],\n            class_id=self.class_id[mask],\n            tracker_id=self.tracker_id[mask]\n            if self.tracker_id is not None\n            else None,\n        )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.from_yolov5","title":"<code>from_yolov5(yolov5_detections)</code>  <code>classmethod</code>","text":"<p>Creates a Detections instance from a YOLOv5 output Detections</p> <p>Attributes:</p> Name Type Description <code>yolov5_detections</code> <code>Detections</code> <p>The output Detections instance from YOLOv5</p> <p>Returns:</p> Example <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from supervision import Detections\n\n&gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n&gt;&gt;&gt; results = model(frame)\n&gt;&gt;&gt; detections = Detections.from_yolov5(results)\n</code></pre> Source code in <code>supervision/detection/core.py</code> <pre><code>@classmethod\ndef from_yolov5(cls, yolov5_detections):\n    \"\"\"\n    Creates a Detections instance from a YOLOv5 output Detections\n\n    Attributes:\n        yolov5_detections (yolov5.models.common.Detections): The output Detections instance from YOLOv5\n\n    Returns:\n\n    Example:\n        ```python\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; from supervision import Detections\n\n        &gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n        &gt;&gt;&gt; results = model(frame)\n        &gt;&gt;&gt; detections = Detections.from_yolov5(results)\n        ```\n    \"\"\"\n    yolov5_detections_predictions = yolov5_detections.pred[0].cpu().cpu().numpy()\n    return cls(\n        xyxy=yolov5_detections_predictions[:, :4],\n        confidence=yolov5_detections_predictions[:, 4],\n        class_id=yolov5_detections_predictions[:, 5].astype(int),\n    )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.from_yolov8","title":"<code>from_yolov8(yolov8_results)</code>  <code>classmethod</code>","text":"<p>Creates a Detections instance from a YOLOv8 output Results</p> <p>Attributes:</p> Name Type Description <code>yolov8_results</code> <code>Results</code> <p>The output Results instance from YOLOv8</p> <p>Returns:</p> Example <pre><code>&gt;&gt;&gt; from ultralytics import YOLO\n&gt;&gt;&gt; from supervision import Detections\n\n&gt;&gt;&gt; model = YOLO('yolov8s.pt')\n&gt;&gt;&gt; results = model(frame)[0]\n&gt;&gt;&gt; detections = Detections.from_yolov8(results)\n</code></pre> Source code in <code>supervision/detection/core.py</code> <pre><code>@classmethod\ndef from_yolov8(cls, yolov8_results):\n    \"\"\"\n    Creates a Detections instance from a YOLOv8 output Results\n\n    Attributes:\n        yolov8_results (ultralytics.yolo.engine.results.Results): The output Results instance from YOLOv8\n\n    Returns:\n\n    Example:\n        ```python\n        &gt;&gt;&gt; from ultralytics import YOLO\n        &gt;&gt;&gt; from supervision import Detections\n\n        &gt;&gt;&gt; model = YOLO('yolov8s.pt')\n        &gt;&gt;&gt; results = model(frame)[0]\n        &gt;&gt;&gt; detections = Detections.from_yolov8(results)\n        ```\n    \"\"\"\n    return cls(\n        xyxy=yolov8_results.boxes.xyxy.cpu().numpy(),\n        confidence=yolov8_results.boxes.conf.cpu().numpy(),\n        class_id=yolov8_results.boxes.cls.cpu().numpy().astype(int),\n    )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.get_anchor_coordinates","title":"<code>get_anchor_coordinates(anchor)</code>","text":"<p>Returns the bounding box coordinates for a specific anchor.</p> Properties <p>anchor (Position): Position of bounding box anchor for which to return the coordinates.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of shape <code>(n, 2)</code> containing the bounding box anchor coordinates in format <code>[x, y]</code>.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def get_anchor_coordinates(self, anchor: Position) -&gt; np.ndarray:\n    \"\"\"\n    Returns the bounding box coordinates for a specific anchor.\n\n    Properties:\n        anchor (Position): Position of bounding box anchor for which to return the coordinates.\n\n    Returns:\n        np.ndarray: An array of shape `(n, 2)` containing the bounding box anchor coordinates in format `[x, y]`.\n    \"\"\"\n    if anchor == Position.CENTER:\n        return np.array(\n            [\n                (self.xyxy[:, 0] + self.xyxy[:, 2]) / 2,\n                (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n            ]\n        ).transpose()\n    elif anchor == Position.BOTTOM_CENTER:\n        return np.array(\n            [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 3]]\n        ).transpose()\n\n    raise ValueError(f\"{anchor} is not supported.\")\n</code></pre>"},{"location":"detection_utils/","title":"Utils","text":""},{"location":"detection_utils/#generate_2d_mask","title":"generate_2d_mask","text":"<p>Generate a 2D mask from a polygon.</p> Properties <p>polygon (np.ndarray): The polygon for which the mask should be generated, given as a list of vertices. resolution_wh (Tuple[int, int]): The width and height of the desired resolution.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The generated 2D mask, where the polygon is marked with <code>1</code>'s and the rest is filled with <code>0</code>'s.</p> Source code in <code>supervision/detection/utils.py</code> <pre><code>def generate_2d_mask(polygon: np.ndarray, resolution_wh: Tuple[int, int]) -&gt; np.ndarray:\n    \"\"\"Generate a 2D mask from a polygon.\n\n    Properties:\n        polygon (np.ndarray): The polygon for which the mask should be generated, given as a list of vertices.\n        resolution_wh (Tuple[int, int]): The width and height of the desired resolution.\n\n    Returns:\n        np.ndarray: The generated 2D mask, where the polygon is marked with `1`'s and the rest is filled with `0`'s.\n    \"\"\"\n    width, height = resolution_wh\n    mask = np.zeros((height, width), dtype=np.uint8)\n    cv2.fillPoly(mask, [polygon], color=1)\n    return mask\n</code></pre>"},{"location":"draw/","title":"Draw","text":""},{"location":"draw/#draw_line","title":"draw_line","text":"<p>Draws a line on a given scene.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>The scene on which the line will be drawn</p> required <code>start</code> <code>Point</code> <p>The starting point of the line</p> required <code>end</code> <code>Point</code> <p>The end point of the line</p> required <code>color</code> <code>Color</code> <p>The color of the line</p> required <code>thickness</code> <code>int</code> <p>The thickness of the line</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the line drawn on it</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_line(\n    scene: np.ndarray, start: Point, end: Point, color: Color, thickness: int = 2\n) -&gt; np.ndarray:\n    \"\"\"\n    Draws a line on a given scene.\n\n    Parameters:\n        scene (np.ndarray): The scene on which the line will be drawn\n        start (Point): The starting point of the line\n        end (Point): The end point of the line\n        color (Color): The color of the line\n        thickness (int): The thickness of the line\n\n    Returns:\n        np.ndarray: The scene with the line drawn on it\n    \"\"\"\n    cv2.line(\n        scene,\n        start.as_xy_int_tuple(),\n        end.as_xy_int_tuple(),\n        color.as_bgr(),\n        thickness=thickness,\n    )\n    return scene\n</code></pre>"},{"location":"draw/#draw_rectangle","title":"draw_rectangle","text":"<p>Draws a rectangle on an image.</p> <p>Attributes:</p> Name Type Description <code>scene</code> <code>ndarray</code> <p>The scene on which the rectangle will be drawn</p> <code>rect</code> <code>Rect</code> <p>The rectangle to be drawn</p> <code>color</code> <code>Color</code> <p>The color of the rectangle</p> <code>thickness</code> <code>int</code> <p>The thickness of the rectangle border</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the rectangle drawn on it</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_rectangle(\n    scene: np.ndarray, rect: Rect, color: Color, thickness: int = 2\n) -&gt; np.ndarray:\n    \"\"\"\n    Draws a rectangle on an image.\n\n    Attributes:\n        scene (np.ndarray): The scene on which the rectangle will be drawn\n        rect (Rect): The rectangle to be drawn\n        color (Color): The color of the rectangle\n        thickness (int): The thickness of the rectangle border\n\n    Returns:\n        np.ndarray: The scene with the rectangle drawn on it\n    \"\"\"\n    cv2.rectangle(\n        scene,\n        rect.top_left.as_xy_int_tuple(),\n        rect.bottom_right.as_xy_int_tuple(),\n        color.as_bgr(),\n        thickness=thickness,\n    )\n    return scene\n</code></pre>"},{"location":"notebook/","title":"Notebook","text":""},{"location":"notebook/#show_frame_in_notebook","title":"show_frame_in_notebook","text":"<p>Display a frame in Jupyter Notebook using Matplotlib</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>ndarray</code> <p>The frame to be displayed.</p> <code>size</code> <code>Tuple[int, int]</code> <p>The size of the plot. default:(10,10)</p> <code>cmap</code> <code>str</code> <p>the colormap to use for single channel images. default:gray</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision.notebook.utils import show_frame_in_notebook\n\n%matplotlib inline\nshow_frame_in_notebook(frame, (16, 16))\n</code></pre> Source code in <code>supervision/notebook/utils.py</code> <pre><code>def show_frame_in_notebook(\n    frame: np.ndarray, size: Tuple[int, int] = (10, 10), cmap: str = \"gray\"\n):\n    \"\"\"\n    Display a frame in Jupyter Notebook using Matplotlib\n\n    Attributes:\n        frame (np.ndarray): The frame to be displayed.\n        size (Tuple[int, int]): The size of the plot. default:(10,10)\n        cmap (str): the colormap to use for single channel images. default:gray\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision.notebook.utils import show_frame_in_notebook\n\n        %matplotlib inline\n        show_frame_in_notebook(frame, (16, 16))\n        ```\n    \"\"\"\n    if frame.ndim == 2:\n        plt.figure(figsize=size)\n        plt.imshow(frame, cmap=cmap)\n    else:\n        plt.figure(figsize=size)\n        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    plt.show()\n</code></pre>"},{"location":"video/","title":"Video","text":""},{"location":"video/#videoinfo","title":"VideoInfo","text":"<p>A class to store video information, including width, height, fps and total number of frames.</p> <p>Attributes:</p> Name Type Description <code>width</code> <code>int</code> <p>width of the video in pixels</p> <code>height</code> <code>int</code> <p>height of the video in pixels</p> <code>fps</code> <code>int</code> <p>frames per second of the video</p> <code>total_frames</code> <code>int</code> <p>total number of frames in the video, default is None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import VideoInfo\n\n&gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='video.mp4')\n\n&gt;&gt;&gt; video_info\nVideoInfo(width=3840, height=2160, fps=25, total_frames=538)\n\n&gt;&gt;&gt; video_info.resolution_wh\n(3840, 2160)\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>@dataclass\nclass VideoInfo:\n    \"\"\"\n    A class to store video information, including width, height, fps and total number of frames.\n\n    Attributes:\n        width (int): width of the video in pixels\n        height (int): height of the video in pixels\n        fps (int): frames per second of the video\n        total_frames (int, optional): total number of frames in the video, default is None\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import VideoInfo\n\n        &gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='video.mp4')\n\n        &gt;&gt;&gt; video_info\n        VideoInfo(width=3840, height=2160, fps=25, total_frames=538)\n\n        &gt;&gt;&gt; video_info.resolution_wh\n        (3840, 2160)\n        ```\n    \"\"\"\n\n    width: int\n    height: int\n    fps: int\n    total_frames: Optional[int] = None\n\n    @classmethod\n    def from_video_path(cls, video_path: str) -&gt; VideoInfo:\n        video = cv2.VideoCapture(video_path)\n        if not video.isOpened():\n            raise Exception(f\"Could not open video at {video_path}\")\n\n        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = int(video.get(cv2.CAP_PROP_FPS))\n        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n        video.release()\n        return VideoInfo(width, height, fps, total_frames)\n\n    @property\n    def resolution_wh(self) -&gt; Tuple[int, int]:\n        return self.width, self.height\n</code></pre>"},{"location":"video/#videosink","title":"VideoSink","text":"<p>Context manager that saves video frames to a file using OpenCV.</p> <p>Attributes:</p> Name Type Description <code>target_path</code> <code>str</code> <p>The path to the output file where the video will be saved.</p> <code>video_info</code> <code>VideoInfo</code> <p>Information about the video resolution, fps, and total frame count.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import VideoInfo, VideoSink\n\n&gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='source_video.mp4')\n\n&gt;&gt;&gt; with VideoSink(target_path='target_video.mp4', video_info=video_info) as s:\n...     frame = ...\n...     s.write_frame(frame=frame)\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>class VideoSink:\n    \"\"\"\n    Context manager that saves video frames to a file using OpenCV.\n\n    Attributes:\n        target_path (str): The path to the output file where the video will be saved.\n        video_info (VideoInfo): Information about the video resolution, fps, and total frame count.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import VideoInfo, VideoSink\n\n        &gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='source_video.mp4')\n\n        &gt;&gt;&gt; with VideoSink(target_path='target_video.mp4', video_info=video_info) as s:\n        ...     frame = ...\n        ...     s.write_frame(frame=frame)\n        ```\n    \"\"\"\n\n    def __init__(self, target_path: str, video_info: VideoInfo):\n        self.target_path = target_path\n        self.video_info = video_info\n        self.__fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n        self.__writer = None\n\n    def __enter__(self):\n        self.__writer = cv2.VideoWriter(\n            self.target_path,\n            self.__fourcc,\n            self.video_info.fps,\n            self.video_info.resolution_wh,\n        )\n        return self\n\n    def write_frame(self, frame: np.ndarray):\n        self.__writer.write(frame)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.__writer.release()\n</code></pre>"},{"location":"video/#get_video_frames_generator","title":"get_video_frames_generator","text":"<p>Get a generator that yields the frames of the video.</p> <p>Parameters:</p> Name Type Description Default <code>source_path</code> <code>str</code> <p>The path of the video file.</p> required <p>Returns:</p> Type Description <code>Generator[ndarray, None, None]</code> <p>A generator that yields the frames of the video.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import get_video_frames_generator\n\n&gt;&gt;&gt; for frame in get_video_frames_generator(source_path='source_video.mp4'):\n...     ...\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>def get_video_frames_generator(source_path: str) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"\n    Get a generator that yields the frames of the video.\n\n    Args:\n        source_path (str): The path of the video file.\n\n    Returns:\n        (Generator[np.ndarray, None, None]): A generator that yields the frames of the video.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import get_video_frames_generator\n\n        &gt;&gt;&gt; for frame in get_video_frames_generator(source_path='source_video.mp4'):\n        ...     ...\n        ```\n    \"\"\"\n    video = cv2.VideoCapture(source_path)\n    if not video.isOpened():\n        raise Exception(f\"Could not open video at {source_path}\")\n    success, frame = video.read()\n    while success:\n        yield frame\n        success, frame = video.read()\n    video.release()\n</code></pre>"},{"location":"video/#process_video","title":"process_video","text":"<p>Process a video file by applying a callback function on each frame and saving the result to a target video file.</p> <p>Parameters:</p> Name Type Description Default <code>source_path</code> <code>str</code> <p>The path to the source video file.</p> required <code>target_path</code> <code>str</code> <p>The path to the target video file.</p> required <code>callback</code> <code>Callable[[ndarray, int], ndarray]</code> <p>A function that takes in a numpy ndarray representation of a video frame and an int index of the frame and returns a processed numpy ndarray representation of the frame.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import process_video\n\n&gt;&gt;&gt; def process_frame(scene: np.ndarray) -&gt; np.ndarray:\n...     ...\n\n&gt;&gt;&gt; process_video(\n...     source_path='source_video.mp4',\n...     target_path='target_video.mp4',\n...     callback=process_frame\n... )\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>def process_video(\n    source_path: str,\n    target_path: str,\n    callback: Callable[[np.ndarray, int], np.ndarray],\n) -&gt; None:\n    \"\"\"\n    Process a video file by applying a callback function on each frame and saving the result to a target video file.\n\n    Args:\n        source_path (str): The path to the source video file.\n        target_path (str): The path to the target video file.\n        callback (Callable[[np.ndarray, int], np.ndarray]): A function that takes in a numpy ndarray representation of a video frame and an int index of the frame and returns a processed numpy ndarray representation of the frame.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import process_video\n\n        &gt;&gt;&gt; def process_frame(scene: np.ndarray) -&gt; np.ndarray:\n        ...     ...\n\n        &gt;&gt;&gt; process_video(\n        ...     source_path='source_video.mp4',\n        ...     target_path='target_video.mp4',\n        ...     callback=process_frame\n        ... )\n        ```\n    \"\"\"\n    source_video_info = VideoInfo.from_video_path(video_path=source_path)\n    with VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n        for index, frame in enumerate(\n            get_video_frames_generator(source_path=source_path)\n        ):\n            result_frame = callback(frame, index)\n            sink.write_frame(frame=result_frame)\n</code></pre>"}]}
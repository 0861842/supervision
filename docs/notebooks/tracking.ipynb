{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tracking Objects in a Video\n",
                "\n",
                "In some cases, it's important for us to track objects across multiple frames of a video. For example, we may need to figure out the direction a vehicle is moving. In this cookbook, we'll cover how to get a tracker up and running  for use in your computer vision applications.\n",
                "\n",
                "## What is a Tracker?\n",
                "\n",
                "Trackers are a piece of code that identifies objects across frames and assigns them a unique id.  There are a few popular trackers at the time of writing this including ByteTrack and Bot-SORT. Supervision makes using trackers a breeze and comes with ByteTrack built-in. First, let's get our deppendencies installed. \n",
                "\n",
                "## Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "powershell"
                }
            },
            "outputs": [],
            "source": [
                "#!/bin/bash\n",
                "!python -m venv venv\n",
                "!source venv/bin/activate\n",
                "!pip install -q inference \"supervision[assets]\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download a Video Asset\n",
                "\n",
                "First, let's download a video that we can detect objects in. Supervision comes with a great utility to help us hit the ground running. The videos is saved in our local directory and can be accessed with the variable `path_to_video`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from supervision.assets import download_assets, VideoAssets\n",
                "\n",
                "# Download a supervision video asset \n",
                "path_to_video = download_assets(VideoAssets.PEOPLE_WALKING)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tracking Objects\n",
                "\n",
                "Now that we have our video installed, let's get to work on tracking objects. We'll pull in a model from roboflow Inference to detect people in our video. We'll then create a `byte_tracker` object that we'll pass our detections to. This will give us a `tracker_id`. We'll then utilize that tracker id to label our detections with a `label_annotator`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import supervision as sv\n",
                "from supervision.assets import download_assets, VideoAssets\n",
                "from inference.models.utils import get_roboflow_model\n",
                "\n",
                "\n",
                "if __name__ == '__main__':\n",
                "\n",
                "    # Install our video from supervision assets\n",
                "    PATH_TO_VIDEO = download_assets(VideoAssets.PEOPLE_WALKING)\n",
                "\n",
                "    # load the yolov8X model from roboflow inference\n",
                "    model = get_roboflow_model('yolov8n-640')\n",
                "\n",
                "    # get video info from the video path \n",
                "    video_info = sv.VideoInfo.from_video_path(PATH_TO_VIDEO)\n",
                "\n",
                "    # create a trace and label annotator, with dynamic video info\n",
                "    label = sv.LabelAnnotator()\n",
                "\n",
                "    # create a ByteTrack object to track detections\n",
                "    byte_tracker = sv.ByteTrack(frame_rate=video_info.fps)\n",
                "\n",
                "    # get frames iterable from video and loop over them\n",
                "    frame_generator = sv.get_video_frames_generator(PATH_TO_VIDEO)\n",
                "\n",
                "    # create a video sink context manager to write the annotated frames to\n",
                "    with sv.VideoSink(target_path=\"output.mp4\", video_info=video_info) as sink:\n",
                "        for frame in frame_generator:\n",
                "\n",
                "            # run inference on the frame\n",
                "            result = model.infer(frame)[0]\n",
                "\n",
                "            # convert the detections to a supervision detections object\n",
                "            detections = sv.Detections.from_inference(result)\n",
                "\n",
                "            # update detections with tracker ids\n",
                "            tracked_detections = byte_tracker.update_with_detections(detections)\n",
                "\n",
                "            # create label text for annotator\n",
                "            labels = [ f\"{tracker_id}\" for tracker_id in tracked_detections.tracker_id ]\n",
                "\n",
                "            # apply label annotator to frame\n",
                "            annotated_frame = label.annotate(scene=frame.copy(), detections=tracked_detections, labels=labels)\n",
                "\n",
                "            # save the annotated frame to the video sink\n",
                "            sink.write_frame(frame=annotated_frame)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
